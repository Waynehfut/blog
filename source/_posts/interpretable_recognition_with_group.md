---
title: 论文阅读之Interpretable and Accurate Fine-grained Recognition via Region Grouping
date: 2020-10-15T20:53:47+08:00
tags: [深度学习, 论文阅读]
categories: 论文
mathjax2: true
toc: true
---

本文是 CVPR 2020 年的 Oral talk。来自威斯康星麦迪逊分校的黄子煊和 Yin Li 完成，文章提出了具有可解释性的深度模型，核心是将基于目标物体的组成部分区域的发现和该识别整合到深度神经网络中。通过分割出目标物体的特定组成部分并且得出该组成部分对最终分类的影响大小，从而实现对物体的组成解释。特别的，通过先搜索物体具体部分区域可能出现的简单先验，可以在无监督的情况下得出物体的组成部分区域。文章证明了，**将基于区域的部分发现和分类成因相结合可以提高模型最终的性能**。

<!-- more -->

## 思路

文章首先是提出了深度学习模型虽然应用的非常广泛，但是作出最终结果的依据是什么，还无法从模型中直接得到直观的解释，作者认为如果能够在得到分类后，再给出分类类别所对应的各个组成区域，那么对于使用者而言会更有价值。同时，如果可以将细分得到的组成具体部分给出它最终分类重要性影响，会更有实际价值。这个思路实际上在基于 CAM 的相关方法中已经有了较多的体现，但是基于 CAM 的方法由于使用的是全局特征图，虽然可以给出全局区域对最终分类的影像，但是无法给出具体的区域。这也是这篇论文认为它的主要贡献之一。

而具体执行时，文章将执行步骤分为了两个大的部分：（1）区域发现；（2）重要性分析。

文章的核心部分就在于，作者提出了一个先验知识，即同一个大类的物体往往是共享相似特征的，这也给了作者启示，可以使用卷积网络的特征可以用来将视觉上相干的区域划分到一组中，这样后续重要性分析甚至可以简单到使用二叉树来做。虽然这么讲好像很有道理的样子，但是实际情况是很多的数据只有弱标签，因此文章假设了一个先验知识来作为引导，即认为一个图片中的一个部分会出现大部分的图片中（如，鸟类的头会出现在大部分鸟类图片中），并服从[Beta 分布](https://www.zhihu.com/question/30269898/answer/123261564)，那么只要在后续证明事实服从 Beta 分布，那么就可以进行下一步重要性分析了。

具体执行时，首先模型需要学习出一组目标字典，作者希望这个字典里里面包含的是一组组成目标物体的“部分”，这个字典是由 2D 的特征图映射得出，并不断比较像素的特征和字典所对应的类别来优化后续的选择。所得到的组成部分字典将在后续注意力机制中依据分类的结果来筛选出来。在训练时，作者认为每个“部分”的出现概率服从 Beta 分布，为了将特征字典再投射到分布中，作者说他们使用了[Earth Mover 距离](https://zhuanlan.zhihu.com/p/145739750)来最小化“部分”出现的先验分布和经验分布来实现，从而在每个 Mini-batch 中将“部分”转换为二值化表示。

## 实施方法

在读这篇论文的时候，最困难的部分就是数学部分的表述不理解，这里重点需要关注几个点

- Beta 分布：可以理解为概率的概率分布，比如说，知晓了一个事情发生的大致概率，对于接下来发生的事件进行概率预测时，就可以基于这个我们已经知道的大概概率进行预估，也就是这篇文章所提出的先验信息。这个方法可以解决因为观测次数不够而导致的可能的预测偏差，也可以随着训练过程提高对参数估计的精度。
- Earth Mover 距离：可以理解为两个不同的分布之间进行转换时需要的“代价”，文中提出的是最小化“部分”寻找到的先验和经验分布的转换代价
- U 形分布：直观上看就是两端多中间少，文中认为图像中的特征分布也会类似的情况，即对于特征来说，会呈现概率上的有和无的状态。文章认为图像中的特征的分布是符合 U 形分布的 Beta 分布的，因此设计了正则化方法将特征字典扔到 Earth Mover 距离中进行度量，这样即可以随着训练的迭代来不断调整特征对应的概率，从而给出在先验“部分”特征出现概率时进一步预测“部分”的重要性。

![文章结构图](https://i.loli.net/2020/10/16/OwHCU6KDpbdRhGE.png)

文章将从三个步骤来实施：

- **“部分”分割**：自特征图中将图像分为多个子“部分”区域（以下简称区域）组，记作$g(\cdot)$；
- **区域特征提取和特征归因发现**：使用池化方法提取区域特征并通过给每个特征区域添加注意力向量，记作$f(\cdot)$；
- **基于注意力的区域分类**：对每个向量通过注意力机制计算注意力向量的值，记作$h(\cdot)$。

在进一步阅读之后，我把这部分形式化表示进行了一个总结，以便于后期查找：

- $X_{1:N}=\{X_n\}$：表示有 N 个 2D 图片的特征图集合，其中 $X_{n}\in R^{D\times H\times W}$ ，表示卷积网络从 $H\times W$ 的二维图像中获得的 D 维的特征，是一个维度为 $D\times H\times W$ 的矩阵。
- $y_{1:n}=\{y_n\}$：表示 N 个图片对应的分类，其中 $y_n \in [1,...,c]$ ，需要注意的是这部分的标签只是大类别的标签，并没有细的类别。
- $D \in R^{D\times K}$：区域组成“部分”的字典，即有哪些区域，其中 $D=[d_1,d_2,...,d_K]$ ，而 $d_k$ 则是代表了一个区域。
- $\hat{y}=\phi(X_i,D;\theta)$：用来分类的决策函数，这个函数在分类时，将特征图 $X_i$ 和全局的字典 $D$ 都考虑在内， $\theta$ 代表优化时的参数，从后续文字可以得知，此部分的优化实际上包括部分区域分割 $Q$ 、区域特征提取和归因 $[Z,a]$ 以及基于注意力的分类 $\hat{y}$ 的函数及对应参数$\theta_g,\theta_f,\theta_c$ 。（注：后续对下标$n$可能不做具体标注）
- $Q=g(X,D,;\theta_g)$: 表示的是区域分配的优化目标，目的是为了通过比对 2D 的特征图 $X$ 和区域字典 $D$ 生成一个区域分配图 $Q \in R^{K\times H\times W}$, 记作 $g(\cdot)$。
- $[Z,a]=f(X,Q,D;{\theta}_{f})$：主要负责了区域特征提取和归因分析，在前一步的区域选择中已经通过区域字典 $D$ 搞定了区域分配图 $Q$ 之后，这块主要是来得到区域内的特征 $Z\in R^{D\times K}$ 并设定一个注意力参数 $a\in R^K$来控制所对应区域在最终分类中的重要性，以供后续继续优化，记作 $f(\cdot)$。
- $\hat{y}=h(Z,a;\theta_c)$：表示的是基于注意力的分类，通过将注意力参数 $a$ 和区域特征 $Z$ 放到线性分类器中，即可通过训练以适应数据，记作 $h(\cdot)$。

但是有个很严肃的问题是，文章认为它需要从弱标签里来学习到对应区域，为了确保“部分”目标的字典可以学习得到，作者假设图片上的特征是从属于一个图片特征集合的，而这个集合即服从 U 形分布，那么这一组特征在图片上可能的概率便可以使用 U 形分布，正则化工作也就是在这部分进行。具体而言，对于给定的一个图片特征集合 $X_{1:N}$ ，假设 $p(d_k|X_{1:N})$ 是区域 $d_k$ 出现在这个集合中的条件概率，并假定 $p(d_k|X_{1:N})$ 概率服从 U 形分布，从而可以控制特征是否存在的概率。**_这个部分还有一个疑惑就是这个概率分布的事件是什么，即事件的直方图是什么_**。作者在文中并没有做进一步的解释，而是认为对于部分简单的同类图像会包含相同的特征，即小规模的数据集Cub-200 birds中，鸟的各个部分特征都是存在的，因此会将这个特征是否存在这个事件置为发生，否则对于复杂的数据集中，则置为未发生。

### 部分分割与正则化

#### 区域分配

#### 区域发现

#### 发现区域的正则化

### 区域特征提取及归因分析

### 基于注意力的分类

## 实验效果

![执行效果](https://i.loli.net/2020/10/16/2XjhnWKZ3MtwvPQ.png)

## 文章预览

{% pdf ./manu.pdf %}
