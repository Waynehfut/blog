---
title: 论文阅读之Interpretable and Accurate Fine-grained Recognition via Region Grouping
date: 2020-10-15T20:53:47+08:00
tags: [深度学习, 论文阅读]
categories: 论文
mathjax2: true
toc: true
---

## 概览

本文是 CVPR 2020 年的 Oral talk。来自威斯康星麦迪逊分校的黄子煊和 Yin Li 完成，文章提出了具有可解释性的深度模型，核心是将基于目标物体的组成部分区域的发现和该识别整合到深度神经网络中。通过分割出目标物体的特定组成部分并且得出该组成部分对最终分类的影响大小，从而实现对物体的组成解释。特别的，通过先搜索物体具体部分区域可能出现的简单先验，可以在无监督的情况下得出物体的组成部分区域。文章证明了，**将基于区域的部分发现和分类成因相结合可以提高模型最终的性能**。

<!-- more -->

## 思路

文章首先是提出了深度学习模型虽然应用的非常广泛，但是作出最终结果的依据是什么，还无法从模型中直接得到直观的解释，作者认为如果能够在得到分类后，再给出分类类别所对应的各个组成区域，那么对于使用者而言会更有价值。同时，如果可以将细分得到的组成具体部分给出它最终分类重要性影响，会更有实际价值。这个思路实际上在基于 CAM 的相关方法中已经有了较多的体现，但是基于 CAM 的方法由于使用的是全局特征图，虽然可以给出全局区域对最终分类的影像，但是无法给出具体的区域。这也是这篇论文认为它的主要贡献之一。

而具体执行时，文章将执行步骤分为了两个大的部分：（1）区域发现；（2）重要性分析。

文章的核心部分就在于，作者提出了一个先验知识，即同一个大类的物体往往是共享相似特征的，这也给了作者启示，可以使用卷积网络的特征可以用来将视觉上相干的区域划分到一组中，这样后续重要性分析甚至可以简单到使用二叉树来做。虽然这么讲好像很有道理的样子，但是实际情况是很多的数据只有弱标签，因此文章假设了一个先验知识来作为引导，即认为一个图片中的一个部分会出现大部分的图片中（如，鸟类的头会出现在大部分鸟类图片中），并服从[Beta 分布](https://www.zhihu.com/question/30269898/answer/123261564)，那么只要在后续证明事实服从 Beta 分布，那么就可以进行下一步重要性分析了。

具体执行时，首先模型需要学习出一组目标字典，作者希望这个字典里里面包含的是一组组成目标物体的“部分”，这个字典是由 2D 的特征图映射得出，并不断比较像素的特征和字典所对应的类别来优化后续的选择。所得到的组成部分字典将在后续注意力机制中依据分类的结果来筛选出来。在训练时，作者认为每个“部分”的出现概率服从 Beta 分布，为了将特征字典再投射到分布中，作者说他们使用了[Earth Mover 距离](https://zhuanlan.zhihu.com/p/145739750)来最小化“部分”出现的先验分布和经验分布来实现，从而在每个 Mini-batch 中将“部分”转换为二值化表示。

## 实施方法

在读这篇论文的时候，最困难的部分就是数学部分的表述不理解，这里重点需要关注几个点

- Beta 分布：可以理解为概率的概率分布，比如说，知晓了一个事情发生的大致概率，对于接下来发生的事件进行概率预测时，就可以基于这个我们已经知道的大概概率进行预估，也就是这篇文章所提出的先验信息。这个方法可以解决因为观测次数不够而导致的可能的预测偏差，也可以随着训练过程提高对参数估计的精度。
- Earth Mover 距离：可以理解为两个不同的分布之间进行转换时需要的“代价”，文中提出的是最小化“部分”寻找到的先验和经验分布的转换代价
- U 形分布：直观上看就是两端多中间少，文中认为图像中的特征分布也会类似的情况，即对于特征来说，会呈现概率上的有和无的状态。文章认为图像中的特征的分布是符合 U 形分布的 Beta 分布的，因此设计了正则化方法将特征字典扔到 Earth Mover 距离中进行度量，这样即可以随着训练的迭代来不断调整特征对应的概率，从而给出在先验“部分”特征出现概率时进一步预测“部分”的重要性。

![文章结构图](https://i.loli.net/2020/10/16/OwHCU6KDpbdRhGE.png)

文章将从三个步骤来实施：

- “部分”分割：自特征图中将图像分为多个子“部分”区域（以下简称区域）组，记作$g(\cdot)$；
- 区域特征提取和特征归因发现：使用池化方法提取区域特征并通过给每个特征区域添加注意力向量，记作$f(\cdot)$；
- 基于注意力的区域分类：对每个向量通过注意力机制计算注意力向量的值，记作$h(\cdot)$。

但是有个很严肃的问题是，文章认为它需要从弱标签里来学习到对应区域，为了确保“部分”目标的字典可以学习得到，作者假设图片上的特征是从属于一个图片特征集合的，而这个集合即服从 U 形分布，那么这一组特征在图片上可能的概率便可以使用 U 形分布，正则化工作也就是在这部分进行。

### 形式化表示

### 部分分割与正则化

#### 区域分配

#### 区域发现

#### 发现区域的正则化

### 区域特征提取及归因分析

### 基于注意力的分类

## 实验效果

![执行效果](https://i.loli.net/2020/10/16/2XjhnWKZ3MtwvPQ.png)

## 文章预览

{% pdf ./manu.pdf %}
