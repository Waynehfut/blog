---
title: 论文阅读之 PANet Few-Shot Image Semantic Segmentation With Prototype Alignment
date: 2020-11-12 17:20:43
tags: [深度学习, 论文阅读]
categories: 论文
mathjax2: true
toc: true
---

本文是 2019 ICCV 的文章，由新加坡国立的电子与计算机工程系[学习与视觉实验室](https://www.ece.nus.edu.sg/lv/index.html)的 Wang, KaiXin 等人完成^[注意：在 CVPR2018 中，有同名模型的文章，做的是实例分割，请参阅[此处](https://github.com/ShuLiu1993/PANet)]。文章的目标是解决小样本数据中的图像分割问题，主要策略是使用 Prototype Alignment (原型分配)的方式将 Prototypical Network 中的距离度量思想用到了图像分割领域，实现流程上，文章使用了支持集和查询集互对齐的方式将支持集查找的原型分配交给查询集，查询集将依据此得到新的查询集原型，而这部分的原型应当可以用于支持集的分割，分割的结果将通过 PAR (原型分配正则化)的方式实现区域特征的对齐。其中，文中对于原型的训练使用了非参数度量的学习方式，将分割任务转换为逐像素的分类，最终实现了较好的实验效果。

<!-- more -->

## 相关背景

文章解决的是图像分割问题，在已有方案中，基于 FCN,SegNet,Deeplab 和 PSPNet 的语义分割网络已经得到了较好的应用，但是从越发复杂的网络结构中可以看出，这些网络所需的训练数据相对较多。虽然有半监督或弱监督的方法可以实现语义的分割，但是仍然需要较多的弱注释的数据来训练模型。此外，最核心的问题是，如果这些模型去分割尚未见过的模型，效果一般都不会太好。为此有了一众小样本学习的研究，目前主要还是集中在分类领域中，对于分割领域而言，相对较少。(关于小样本学习的内容，请参见[论文阅读之 Prototypical Network for Few-Shot Learning](https://blog.waynehfut.com/2020/11/02/prototypical_network_for_few_shot_learning/)

无论是度量的算法或是其他方法，现有的小样本学习通常策略是从少量的支持集中学习知识，之后传入到查询集中在进行其他任务。但是作者认为这样的方式存在知识发现和分割过程是混合在一起的问题，可能会将分割模型表示和语义特征混到一起导致特征提取问题。为此作者分了两步来实施工作，分别为原型提取和非参数度量学习。通俗的说，就是分两步来做分割，第一步是提取原型，即将图像像素嵌入到原型中，实际是一种编码过程；第二步是在原型特征图上做基于像素分类的图像分类。但是这样的方式其实在基于 RPN 的网络中是比较常见的思路，作者在这部分更多的是添加了小样本的背景来魔改前人的工作。文章的重点是后续所提的原型分配正则化，这部分内容是通过将两步有监督的分割结果正则化后反向对齐分割结果实现的。如下图所示，其中圆形的是支持集中的嵌入特征，三角形的为查询集的嵌入特征，第一步所做的工作是支持集到查询集的原型特征抽取，即将查询集的所有特征嵌入到特定原型中，从而形成了右侧第二步的查询集原型空间，新的原型空间可以作为逐像素分类的先验信息并在支持集上得出基于支持集的图像分割结果，这一结果可以与支持集的标签进行损失计算。简单来说就是支持集的原型可以在查询集预测到结果，这部分查询集及其预测结果可以作为新的支持集来分割支持集中的数据，并最终比较有标签标注的正则化数据，以获得正则化损失。需要注意的是，这个正则化过程是在训练过程中做的，查询集和 PAR 损失计算的图像是无关的。

![PANet示意图](https://raw.githubusercontent.com/Waynehfut/blog/img/img/20201117150836.png)

作者认为模型基于这样的方式避免了引入新参数的问题，避免了过拟合问题，同时避免了额外网络的辅助，基于正则化的对齐方式也降低了计算量。作者还在实验中尝试了非精确的涂鸦标记，同样得到了较好的效果。

## 实现细节

大体上，文章的数据分治思路与原有小样本学习没有太大区别，数据定义中需要注意，因为涉及到语义分割，因而其类别是依据语义类别来划分的。此外还需重点关注训练策略。

### 符号定义

- $\mathcal{C}_{seen}$ 和 $\mathcal{C}_{unseen}$ 是两个互不重合的图像集合，分别从中可得到 $\mathcal{D}_{train}$ 和 $\mathcal{D}_{test}$；
- $\mathcal{D}_{train}$ 和 $\mathcal{D}_{test}$ 表示训练集和测试集，同时在每次 Few-shot 的训练 (episode) 中，都会从这两个集合抽取部分不重复的数据，称之为 $\mathcal{S}$ 和 $\mathcal{Q}$，通常称为支持集和查询集。则训练集和测试集可以表示为 $\mathcal{D}_{train} = \{(\mathcal{S}_i,\mathcal{Q}_i)\}_{i=1}^{N_{train}}$ 和 $\mathcal{D}_{test} = \{(\mathcal{S}_i,\mathcal{Q}_i)\}_{i=1}^{N_{test}}$，其中 $N_{train}$ 和 $N_{test}$ 分别表示训练集和测试集的总数量，这里可以类比前述 Few-shot 学习中对于 Training Task 和 Test Task 的定义；
- 每次训练（episode）中的 $(\mathcal{S}_i,\mathcal{Q}_i)$ 实例中会 $K$ 个样本 $<image,mask>$ 其中这些样本下每个都有包含 $C$ 个语义类别，也被称为 `C-Way-K-shot`，例如对于$\mathcal{S}_i=\{(I_{c,k},M_{c,k})\}$而言，其中 $k=1,2,...,k$，并且$c\in\mathcal{C}_i$, $|\mathcal{C}_i|=C$。而查询集$\mathcal{Q}_i$包含$N_{query} <image, mask>$个图像对，且总共的类别与支持集$\mathcal{S}_i$相同.
- 所训练的模型$\mathcal{M}$就是在每次训练（episode）从支持集中找特征并应有到查询集中。

### 模型概览

![模型流程](https://raw.githubusercontent.com/Waynehfut/blog/img/img/20201121221328.png)

首先模型将使用共享权值的 VGG-16 作为 backbone 来提取特征，之后使用 average pooling 从支持集中获取原型集，之后（a）步骤用这些原型集在查询集上计算每个像素到原型的距离，取最近距离来划分区域原型，得到查询集分割结果并进一步得到查询集原型,（b）步骤中这个原型再返回支持集获得支持集分割结果，同时作者还设计了一个原型对齐正则化 PAR 来约束（a) 和（b）两个步骤学习到的嵌入方式一致。

听上去很玄乎，但是其实仔细看来就是两轮结果与原始Ground Truth对齐的过程，只是这个过程作者用一个比较玄乎的PAR来描述而已。

### 原型获取

模型的目标是在每个语义类上学习细分的原型表示，简单来说就是把每个语义分割的目标嵌入到原型中，作者同时考虑了背景类，这个方法参考了[原型网络](https://blog.waynehfut.com/2020/11/02/prototypical_network_for_few_shot_learning/)，稍有不同的是，这篇文章使用的是掩膜来在整张图上分别学习前景和后景，采用了后融合的策略在输入的图像特征图上进行掩膜上分别进行前景和背景的提取。

### 非参数度量学习

### 原型分配正则化

## 实验细节

[代码](https://github.com/kaixin96/PANet)
